---
replicas: 1

# Allows you to add any config files in /usr/share/logstash/config/
# such as logstash.yml and log4j2.properties
#
# Note that when overriding logstash.yml, `http.host: 0.0.0.0` should always be included
# to make default probes work.
logstashConfig: 
  logstash.yml: |
    http.host: 0.0.0.0
#   monitoring.enabled: false
#   xpack.monitoring.elasticsearch.hosts: ["https://elasticsearch-master:9200"]
#   xpack.monitoring.elasticsearch.username: '${ELASTICSEARCH_USERNAME}'
#   xpack.monitoring.elasticsearch.password: '${ELASTICSEARCH_PASSWORD}' 
#   xpack.monitoring.elasticsearch.ssl.certificate_authority: "/usr/share/logstash/certs/ca.crt"
#   xpack.monitoring.elasticsearch.ssl.verification_mode: none
#    key:
#      nestedkey: value
#  log4j2.properties: |
#    key = value

# Allows you to add any pipeline files in /usr/share/logstash/pipeline/
### ***warn*** there is a hardcoded logstash.conf in the image, override it first
logstashPipeline:
  logstash.conf: |
    input {
      beats {
        port => 5044
        ssl_certificate_authorities => ["/usr/share/logstash/certs/ca.crt"]
        ssl_client_authentication => "optional"
        ssl_enabled => true
        ssl_certificate => "/usr/share/logstash/certs/log.crt"
        ssl_key => "/usr/share/logstash/keylog/log.key"
      }
    }
    filter {
      if [kubernetes][pod][name] == "nginx" {
        grok {
          match => { "message" => "%{COMBINEDAPACHELOG}" }
        }
        mutate { add_field => { "show" => "Test filter logstash" } }
      }
      if [kubernetes][pod][name] == "logstash-logstash-0" {
        grok {
          match => { "message" => "%{TYPE_MESSAGE:type_message}" }
        }
        mutate { 
          add_field => { "show_test" => "Test filter logstash" } 
        }
      }
      date {
        match => [ "timestamp", "MM dd yyyy HH:mm:ss Z" ]
      }
    }
    output {
      if [kubernetes][pod][name] == "nginx" {
        elasticsearch {   
          ilm_rollover_alias => "nginx"
          ilm_pattern => "000001"
          ilm_policy => "app-log-policy"
          hosts => [ "https://elasticsearch-master:9200" ]
          user => '${ELASTICSEARCH_USERNAME}'
          password => '${ELASTICSEARCH_PASSWORD}' 
          ssl_verification_mode => none
        }
      }else if [kubernetes][pod][name] == "logstash-logstash-0" {
        elasticsearch {   
          ilm_rollover_alias => "logstash"
          ilm_pattern => "000001"
          ilm_policy => "app-log-policy"
          hosts => [ "https://elasticsearch-master:9200" ]
          user => '${ELASTICSEARCH_USERNAME}'
          password => '${ELASTICSEARCH_PASSWORD}' 
          ssl_verification_mode => none
        }
      }else {
        elasticsearch {
          ilm_rollover_alias => "log-app"
          ilm_pattern => "000001"
          ilm_policy => "app-log-policy"
          hosts => [ "https://elasticsearch-master:9200" ]
          user => '${ELASTICSEARCH_USERNAME}'
          password => '${ELASTICSEARCH_PASSWORD}' 
          ssl_verification_mode => none
        }
      }
    }

# ssl_certificate_authorities => ["/usr/share/logstash/certs/ca.pem"]
# ssl_certificate => "/usr/share/logstash/certs/log.crt"
# ssl_key => "/usr/share/logstash/certs/log.pem"
#  ssl_verification_mode => none
# Allows you to add any pattern files in your custom pattern dir
logstashPatternDir: '/usr/share/logstash/patterns/'
logstashPattern: 
  pattern.conf: |
    TYPE_MESSAGE [A-Z]{4,5}

# Extra environment variables to append to this nodeGroup
# This will be appended to the current 'env:' key. You can use any of the kubernetes env
# syntax here
extraEnvs:
  - name: 'ELASTICSEARCH_USERNAME'
    valueFrom:
        secretKeyRef:
            name: elasticsearch-master-credentials
            key: username
  - name: 'ELASTICSEARCH_PASSWORD'
    valueFrom:
        secretKeyRef:
            name: elasticsearch-master-credentials
            key: password

# Allows you to load environment variables from kubernetes secret or config map
envFrom: []
# - secretRef:
#     name: env-secret
# - configMapRef:
#     name: config-map

# Add sensitive data to k8s secrets
secrets:
#  - name: "env"
#    value:
#      ELASTICSEARCH_PASSWORD: "LS1CRUdJTiBgUFJJVkFURSB"
#      api_key: ui2CsdUadTiBasRJRkl9tvNnw
  - name: "tls"
    value:
      log.key: |
        -----BEGIN PRIVATE KEY-----
        MIIEvwIBADANBgkqhkiG9w0BAQEFAASCBKkwggSlAgEAAoIBAQCx69iNvqv/tH5r
        GDdS3aF8VBWyVCgwV0dx+kmztTkN2Jdi8HHdpTfVNTGM4xtdspRvTQaDv79e+tiL
        gJ+pslVyyKhz052aJhjDdu4a+kiZTm8UCnlDbzCxCf+WTsmrUWVA3byeUUDs0rvh
        jPUKOrj1LBQAfjFJkxXgxIQD/nG4S1a25EnSGGFEXob27NEtTlu/OQJppTC1UN1o
        WmQ8mGcayV9aWU2JIQJSDPGYgpdWLSPbwxQI4BWypAVGRcIE+fw88ADGhpzu34Z6
        M88UqwGS2CdCH6dZzHs+W8+I5dTghRKdJKWUdZSfPpgyGmY0XnDD4iIdNYwqKbZp
        FL9WUSzlAgMBAAECggEBAKNntgXInnNEM+7r2LO0dYGYQCz9+cMcBbP6aQIxaGr9
        B1yI9CraeMLKDe4VDqcpQgZOubL6winbPFIzGXBjJvM6sutd6RsP7iJm8hu4zkBu
        trmzPNfgINoYErLbPYCoStQeUgMdIQHgMUnfiZWRhRk3GE+zllS6T5eVJKH+aDcX
        AlEC8JaeDBZ/S2NuGsgOwmeSwL7zaU2uVgpQfS8RvcmICnjcxY7XGlnr0wF3J7sk
        9Bo8cQ53EAFHZIKsh5fb36fRF+IniGxTxZHIWarn7swQURn4EPIAscYJcLVxcu1b
        ppmaxfJp/OJeoziVcJpxO9FNlp5/SCNsqFrkFsSg+akCgYEA1lFp/XDSfmngSDtB
        f24vmhK56svFnYxhGZzN0D0fEa6i5VFftxSgG6oBbW2aPTEuOA+442SB9mvFEIbf
        8tHFxuV+Jk75X6RErTZvwMAO0OpxuhEwNg4Mmdp7TcvowNWkGj0w6iNB157Mb4EW
        1atNCS71833t3CxIx/D60PK98oMCgYEA1IZKQYTpfsPRVgVAb4BRwkjsldGgJmsB
        3hxzgwvsYzbkeb3zpgGluFoMkS93Y/5fs5lFdQM7AXo8L+JC0BvJwLy6KuPBbHfv
        REBlzIc3Y/oXPnkKAQ/s8sHRA3LSFdwDvGzGHUK9jauuhacVisTCEHlUkqyPFmOC
        ejj/u6MCJncCgYBQxFnHM0+AaHInhn1GgsXZsJj0DVsp5o9pUZiWk5Iz3bZx6VrC
        6jj0c/sZvCZWTUR3yCULPQNlVHPtqIaZQcjhDfeehECidIuVI2C2KSrsPI4javra
        RC0nhhjV1rSeh2TSpqDae/MCSUwN8X4jg+0COvphiuGrCd1bzEsZl4FR9QKBgQCx
        EHmJgP0w+mDMtG9s9pIntq42XIJ7v6e8sCOlSSfXuYI90/7Njo3NvGjABbYI/4Qo
        lEiEJv7gSkEe+/oCfURoalUJKtyaTIpyaNznvLhveYwoJpwpKmWWE9jacK2MPNR4
        BoBBHLvk7ubmv8B471lodE38LfzBAINS5W5bnIJMHQKBgQCJKXBVwtlWNas66cxs
        7/Ju810VDPzIZEaIsQbx2JSLlyRZexuqnrfayYVnfpPY5LiVbu6mMLAcmJXW0Vit
        QgvL3yq6eLlDejJXqY+1C+i4Z09bwZsgqxegtbhjHmRMk5CgSuhDT7HKWysgPLGR
        ouawNTF4aFLgYc+Pz1m6jE/0mg==
        -----END PRIVATE KEY-----

# A list of secrets and their paths to mount inside the pod
secretMounts:
  - name: logstash-certs
    secretName: elasticsearch-master-certs
    path: /usr/share/logstash/certs/
  - name: log-certs
    secretName: logstash-logstash-tls 
    path: /usr/share/logstash/keylog/

hostAliases: []
#- ip: "127.0.0.1"
#  hostnames:
#  - "foo.local"
#  - "bar.local"

image: 'docker.elastic.co/logstash/logstash'
imageTag: '8.14.1'
imagePullPolicy: 'IfNotPresent'
imagePullSecrets: []

podAnnotations: {}

# additionals labels
labels: {}

logstashJavaOpts: '-Xmx1g -Xms1g'

resources:
  requests:
      cpu: '200m'
      memory: '1536Mi'
  limits:
      cpu: '500m'
      memory: '1536Mi'

volumeClaimTemplate:
  accessModes: ['ReadWriteOnce']
  resources:
      requests:
          storage: 2Gi

rbac:
  create: false
  serviceAccountAnnotations: {}
  serviceAccountName: ''
  annotations:
      {}
      #annotation1: "value1"
      #annotation2: "value2"
      #annotation3: "value3"

podSecurityPolicy:
  create: false
  name: ''
  spec:
      privileged: false
      fsGroup:
          rule: RunAsAny
      runAsUser:
          rule: RunAsAny
      seLinux:
          rule: RunAsAny
      supplementalGroups:
          rule: RunAsAny
      volumes:
          - secret
          - configMap
          - persistentVolumeClaim

persistence:
  enabled: false
  annotations: {}

extraVolumes:
  []
  # - name: extras
  #   emptyDir: {}

extraVolumeMounts:
    []
    # - name: extras
    #   mountPath: /usr/share/extras
    #   readOnly: true

extraContainers:
    []
    # - name: do-something
    #   image: busybox
    #   command: ['do', 'something']

extraInitContainers:
    []
    # - name: do-something
    #   image: busybox
    #   command: ['do', 'something']

# This is the PriorityClass settings as defined in
# https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass
priorityClassName: ''

# By default this will make sure two pods don't end up on the same node
# Changing this to a region would allow you to spread pods across regions
antiAffinityTopologyKey: 'kubernetes.io/hostname'

# Hard means that by default pods will only be scheduled if there are enough nodes for them
# and that they will never end up on the same node. Setting this to soft will do this "best effort"
antiAffinity: 'hard'

# This is the node affinity settings as defined in
# https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
nodeAffinity: {}

# This is inter-pod affinity settings as defined in
# https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
podAffinity: {}

# The default is to deploy all pods serially. By setting this to parallel all pods are started at
# the same time when bootstrapping the cluster
podManagementPolicy: 'Parallel'

httpPort: 9600

# Custom ports to add to logstash
extraPorts:
    []
    # - name: beats
    #   containerPort: 5001

updateStrategy: RollingUpdate

# This is the max unavailable setting for the pod disruption budget
# The default value of 1 will make sure that kubernetes won't allow more than 1
# of your pods to be unavailable during maintenance
maxUnavailable: 1

podSecurityContext:
    fsGroup: 1000
    runAsUser: 1000

securityContext:
    capabilities:
        drop:
            - ALL
    # readOnlyRootFilesystem: true
    runAsNonRoot: true
    runAsUser: 1000

# How long to wait for logstash to stop gracefully
terminationGracePeriod: 120

# Probes
# Default probes are using `httpGet` which requires that `http.host: 0.0.0.0` is part of
# `logstash.yml`. If needed probes can be disabled or overridden using the following syntaxes:
#
# disable livenessProbe
# livenessProbe: null
#
# replace httpGet default readinessProbe by some exec probe
# readinessProbe:
#   httpGet: null
#   exec:
#     command:
#       - curl
#      - localhost:9600

livenessProbe:
    httpGet:
        path: /
        port: http
    initialDelaySeconds: 300
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1

readinessProbe:
    httpGet:
        path: /
        port: http
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 3

## Use an alternate scheduler.
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
schedulerName: ''

nodeSelector: {}
tolerations: []

nameOverride: ''
fullnameOverride: ''

lifecycle:
    {}
    # preStop:
    #   exec:
    #     command: ["/bin/sh", "-c", "echo Hello from the postStart handler > /usr/share/message"]
    # postStart:
    #   exec:
    #     command: ["/bin/sh", "-c", "echo Hello from the postStart handler > /usr/share/message"]

service:
    # annotations: {}
    type: ClusterIP
    # loadBalancerIP: ""
    ports:
        - name: beats
          port: 5044
          protocol: TCP
          targetPort: 5044
        - name: http
          port: 8080
          protocol: TCP
          targetPort: 8080

ingress:
    enabled: false
    annotations:
        {}
        # kubernetes.io/tls-acme: "true"
    className: 'nginx'
    pathtype: ImplementationSpecific
    hosts:
        - host: logstash-example.local
          paths:
              - path: /beats
                servicePort: 5044
              - path: /http
                servicePort: 8080
    tls: []
    #  - secretName: logstash-example-tls
    #    hosts:
    #      - logstash-example.local
